{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro sulla model selection\n",
    "\n",
    "Durante l'ultima lezione, abbiamo parlato dell'utilità del validation set per fare l'early stopping. La scelta del \"modello migliore\" durante il training, valutando la sua performance sul validation set, è un punto chiave della __model selection__.\n",
    "\n",
    "Abbiamo specificato che ci sono due punti in particolare in cui facciamo la model selection:\n",
    "\n",
    "1. Rispetto a diverse configurazioni del modello;\n",
    "2. Data una configurazione, nella fase del training in cui il modello si \"comporta meglio\" sui dati di validazione.\n",
    "\n",
    "La scorsa volta abbiamo visto come soddisfare il secondo punto della model selection, oggi vedremo il primo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning con Keras\n",
    "\n",
    "Nelle prime due lezioni, i modelli che abbiamo utilizzato erano sempre dei modelli con delle configurazioni scelte \"a caso\". Purtroppo, quando creiamo un modello per fare predizioni su nuovi dati, la scelta della configurazione non è una cosa per niente scontata.\n",
    "\n",
    "Ogni modello è dotato di due tipologie di parametri:\n",
    "1. I parametri adattivi, ovvero i pesi della rete neurale, che vengono __adattati durante il training__;\n",
    "2. Gli __iperparametri__, che specificano l'architettura del modello (per esempio, quanti layer deve avere la rete neurale, quante unità per layer), la regolarizzazione, il learning rate, il batch size etc...\n",
    "\n",
    "I secondi sono fissati __prima del training__, e possono rappresentare un fattore determinante nella qualità del modello (con un modello con troppi layer e unità potremmo avere overfitting, nel caso contrario underfitting) e nella qualità del training (un learning rate troppo alto fa divergere il modello, mentre uno troppo basso rallenta troppo il training e potrebbe restituire soluzioni sub-ottime).\n",
    "\n",
    "Al giorno d'oggi, purtroppo, non esiste ancora una \"*formula magica*\" grazie alla quale troviamo la configurazione perfetta. Esistono algoritmi che ottimizzano questa scelta, ma non sono materiale di questo corso.\n",
    "\n",
    "Quindi, ogni buon ML engineer si affida, generalmente, per il 20% all'esperienza e per il rimanente 80%... al caso, ma con \"*tante chances*\". :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tuner\n",
    "\n",
    "[Keras Tuner](https://keras.io/keras_tuner/) è la libreria di alto livello che ci viene offerta da Keras per fare una ricerca di iperparametri.\n",
    "\n",
    "Questa si basa su due componenti principali:\n",
    "\n",
    "1. Uno __spazio di ricerca__, che denota tutte le possibili configurazioni di iperparametri da cui possiamo scegliere;\n",
    "2. Un __algoritmo di ricerca__, che ci dice come dobbiamo muoverci per arrivare al nostro modello ottimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras as K\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search space API\n",
    "\n",
    "La API dello spazio di ricerca offre diverse opzioni per scegliere iperparametri sia categorici che numerici (interi e float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo il nostro spazio di ricerca vuoto chiamando la classe `HyperParameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = HyperParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`khp.Choice` è il candidato ideale per scegliere da un insieme di parametri categorici. Se, per esempio, dovessimo scegliere fra due attivazioni (`tanh` o `relu`), potremmo utilizzare questa funzione per \"scegliere\" fra i due."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.Choice)\n",
    "print(\"Valore di attivazione scelto =\", hp.Choice(name='activation', values=['tanh', 'relu']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hp.Boolean` quando dobbiamo scegliere qualcosa che sia condizionato da un valore di verità. Un esempio può essere se vogliamo utilizzare il bias o meno sull'ultimo layer (`use_bias=True/False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.Boolean)\n",
    "print(\"Valore booleano =\", hp.Boolean(name='use_bias'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hp.Fixed` lo utilizziamo quando vogliamo fissare un parametro. Per esempio, vogliamo che il valore di batch_size sia uguale a 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.Fixed)\n",
    "print(\"Valore di batch size =\", hp.Fixed(name='batch_size', value=32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hp.Float` lo possiamo utilizzare quando vogliamo scegliere valori numerici all'interno di un certo intervallo. Vari esempi di utilizzo possono essere il learning rate, la regolarizzazione e altro ancora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.Float)\n",
    "print(\"Valore del learning rate =\", hp.Float(name='learning_rate', min_value=0.0001, max_value=0.1, sampling='log'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hp.Int` restituisce un valore intero all'interno di un range prestabilito. Può essere utile per scegliere il numero di layers o il numero di unità della nostra rete neurale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(hp.Int)\n",
    "print(\"Il numero di layers della rete è\", hp.Int(name='units', min_value=1, max_value=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora che abbiamo il nostro spazio di ricerca, ovvero `hp`, possiamo anche reperire i valori correnti di ogni elemento stabilito nello spazio di ricerca. Questo ci permette di prendere una configurazione del nostro modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hp.get('units'))\n",
    "print(hp.get('learning_rate'))\n",
    "print(hp.get('batch_size'))\n",
    "print(hp.get('use_bias'))\n",
    "print(hp.get('activation'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutto questo, in realtà, viene fatto in automatico dentro la funzione di \"creazione del modello\", a breve vediamo come."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "\n",
    "Come dicevamo poco fa, un ML engineer fa affidamento per il 20% all'esperienza, e per l'80% a caso. In senso letterale.\n",
    "\n",
    "Con la __Random Search__ definiamo uno spazio di ricerca con un minimo di esperienza (se sappiamo di avere un dataset giocattolo, non utilizzeremo una rete neurale con 50 layers) e creando configurazioni a caso da quello spazio di ricerca.\n",
    "\n",
    "Keras Tuner offre la classe `RandomSearch`, a cui dobbiamo passare:\n",
    "\n",
    "1. Una funzione di __creazione del modello rispetto allo spazio di ricerca__;\n",
    "2. Una funzione obiettivo con cui valuteremo il modello (esempio, loss sul validation set);\n",
    "3. Un numero di tentativi, ovvero di configurazioni che vogliamo provare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione `build_model`, quando utilizzata dentro la random search, ci restituirà configurazioni casuali del modello rispetto allo spazio di ricerca che abbiamo definito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = K.Sequential()\n",
    "    model.add(K.layers.Flatten())\n",
    "    model.add(K.layers.Rescaling(scale=1/255.))\n",
    "\n",
    "    model.add(K.layers.Dense(\n",
    "        units=hp.Choice('units', [50, 100, 1000]),\n",
    "        activation='relu'))\n",
    "    model.add(K.layers.Dense(10, activation='softmax', use_bias=hp.Boolean('use_bias')))\n",
    "\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora creiamo il la nostra `RandomSearch` rispetto al modello fissato, dove generiamo 5 configurazioni casuali. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E vediamo cosa succede con il nostro caro MNIST. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.datasets as kds\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = kds.mnist.load_data(path='ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, eval_X, train_y, eval_y = train_test_split(\n",
    "    train_X, train_y,\n",
    "    test_size=0.15,\n",
    "    shuffle=True,\n",
    "    stratify=train_y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione search espone esattamente gli stessi parametri di `model.fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_X, train_y, epochs=5, batch_size=1000, validation_data=(eval_X, eval_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "prediction = best_model(train_X[:10])\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].get_config()['values']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn!\n",
    "\n",
    "Prendete il lavoro che avete fatto la scorsa volta sul dataset Boston housing e lanciate una RandomSearch esplorando come segue:\n",
    "1. Sul primo layer, esplorate sui parametri `units` e `regularization`, e l'attivazione è `tanh`;\n",
    "2. Il secondo layer è fissato a 100 neuroni, con attivazione `tanh`;\n",
    "3. Il terzo layer ha un solo neurone senza attivazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_train_X, h_train_y), (h_test_X, h_test_y) = kds.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "h_train = np.concatenate([h_train_X, h_train_y[:, np.newaxis]], axis=1)\n",
    "random.seed(42)\n",
    "random.shuffle(h_train)\n",
    "\n",
    "h_train, h_eval = h_train[75:], h_train[:75]\n",
    "h_train_X, h_train_y = h_train[:, :-1], h_train[:, -1]\n",
    "h_eval_X, h_eval_y = h_eval[:, :-1], h_eval[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_train_X.shape, h_train_y.shape), (h_eval_X.shape, h_eval_y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_mela')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3917c018cfd92834e25e8ac39593c8ba50cba5d103d91e5ca7d5a867c45ae1af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
