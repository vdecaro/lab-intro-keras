{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_qWgbSrNdjn"
      },
      "source": [
        "# Introduzione a Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M0crmii8Ysb"
      },
      "source": [
        "Keras è una libreria di alto livello che consente di costruire e sperimentare con modelli di Deep Learning in maniera flessibile.\n",
        "E' integrata con TensorFlow, che fornisce un supporto più di \"basso livello\". Documentazione, tutorial ed esempi sono nel sito web di TF.\n",
        "\n",
        "Documentazione API (andate su `tf.keras`): https://www.tensorflow.org/versions\n",
        "\n",
        "Guide Keras (per componenti API specifici): https://www.tensorflow.org/guide/keras\n",
        "\n",
        "Tutorials (coprono esempi di utilizzo base): https://www.tensorflow.org/tutorials/keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8Q3zv6RjiUt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras as K\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y6WrRhvgA9x3",
        "outputId": "3c5ca909-663a-47c7-d868-2fc1b3c00852"
      },
      "outputs": [],
      "source": [
        "K.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjdGEixplbmc"
      },
      "source": [
        "# Primo training end-to-end con Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI7FoTtS_zPa"
      },
      "source": [
        "Cominciamo dal caricare il nostro dataset di immagini."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY6DQMRuldzC"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.datasets as kds\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bna7Yrs6lgai",
        "outputId": "4e937c41-eeb3-4d9d-d1e9-bab0ee6b2e9d"
      },
      "outputs": [],
      "source": [
        "(train_X, train_y), (test_X, test_y) = kds.mnist.load_data(path='ds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYgUq7q3_zPd",
        "outputId": "63abce63-5671-45f5-adb4-d93c3a578f21"
      },
      "outputs": [],
      "source": [
        "type(train_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCq1BhcSliBq",
        "outputId": "43ad73cf-1998-45a3-a2ad-44e5f1bad441"
      },
      "outputs": [],
      "source": [
        "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_X[0], train_y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "MjCYYuZE_zPe",
        "outputId": "b3afa6d4-990b-436d-928f-ed8e748ee4f1"
      },
      "outputs": [],
      "source": [
        "print(f\"Label is {train_y[0]}\")\n",
        "Image.fromarray(train_X[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bihyoidhljTS",
        "outputId": "44a37b0e-db04-45cc-9680-930e1748d518"
      },
      "outputs": [],
      "source": [
        "train_X.dtype, train_y.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26UpaZ7A9E3V"
      },
      "source": [
        "## Keras Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPik3nwM9yVh"
      },
      "source": [
        "La prima cosa da fare con Keras è costruire la nostra \"__scatola__\" che ci permetterà di processare i dati da input ad output.\n",
        "\n",
        "Vediamo il primo modo di costruirla, che è tramite la __Sequential API__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alvksVvWk4vs"
      },
      "outputs": [],
      "source": [
        "model = K.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9m41arx_zPh"
      },
      "source": [
        "Una pipeline è composta da **layers**.\n",
        "\n",
        "__Un layer è una funzione che, dato un input, restituisce un output che è il risultato della \"trasformazione\" dell'input__. Solitamente (ma, come vedremo fra un attimo, non necessariamente), questo avviene rispetto a parametri adattivi.\n",
        "\n",
        "Un modello si può costruire componendo molti layer, e mette a disposizione anche interfacce per funzionalità più complesse come il training, l'inferenza, ecc...\n",
        "\n",
        "Dentro la Sequential API, possiamo inserire quanti layer vogliamo semplicemente utilizzando `model.add(new_layer)`. __Tutti i layer verranno eseguiti nell'ordine in cui li abbiamo inseriti__.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fu2yYY8_zPh"
      },
      "source": [
        "### Flatten Layer\n",
        "\n",
        "Questo layer ci permette di appiattire i tensori, portandoli da un formato 28x28 a un vettore di lunghezza 784."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcWuYNtw_zPi"
      },
      "outputs": [],
      "source": [
        "model.add(K.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTXkGB4x_zPi"
      },
      "source": [
        "### Rescaling Layer\n",
        "\n",
        "Questo layer riscala i dati applicando la formula `x = x * scale`. La motivazione dietro il rescaling è che vogliamo evitare che i neuroni si **saturino**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY4XGyK1_zPi",
        "outputId": "df741a80-ab3d-4358-d685-cf5eb9624272"
      },
      "outputs": [],
      "source": [
        "help(K.layers.Rescaling.__init__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHhGXV4t_zPj"
      },
      "outputs": [],
      "source": [
        "model.add(K.layers.Rescaling(scale=1./255))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9uhiM8-_zPj"
      },
      "source": [
        "### Dense Layer\n",
        "\n",
        "Questo layer ci permette di implementare qualsiasi funzione che prevede:\n",
        "\n",
        "1. Una funzione lineare del tipo `y = Wx + b`;\n",
        "2. Successivamente, una __funzione di attivazione__, che applica la nonlinearità della rete neurale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fft2dXhg_zPj",
        "outputId": "2b29f38d-494b-48a8-8c3b-084752afe7dc"
      },
      "outputs": [],
      "source": [
        "help(K.layers.Dense.__init__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fOmYJUc_zPk"
      },
      "outputs": [],
      "source": [
        "model.add(K.layers.Dense(1000, activation='relu')) # E la dimensione di input?\n",
        "model.add(K.layers.Dense(200, activation='relu'))\n",
        "model.add(K.layers.Dense(10, activation='softmax')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "l2_reg = K.regularizers.l2(l2=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JntXHeE_zPk"
      },
      "source": [
        "### Compiliamo la pipeline con un ottimizzatore\n",
        "\n",
        "La funzione di compilazione è quella che ci permette di prendere tutti questi pezzetti che stiamo mettendo dentro la Sequential API, e \"incastonarli\" dentro un grafo computazionale.\n",
        "\n",
        "Sarà Keras stesso, a questo punto, a curarsi di quali sono le parti che hanno dei parametri adattivi (che quindi hanno bisogno di gradiente) e quali no, rispetto al modo in cui sono definiti i layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMwPvPZG_zPk",
        "outputId": "6449e553-2738-467f-9c64-0e30a536fecc"
      },
      "outputs": [],
      "source": [
        "help(model.compile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhvHTj_m_zPl"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=K.optimizers.Adam(learning_rate=0.1),\n",
        "    loss=K.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La __regolarizzazione__ è uno strumento fondamentale per ridurre la probabilità di __overfitting__ del nostro modello.\n",
        "\n",
        "Generalmente, valori molto grandi dei pesi di un modello sono associati all'overfitting. Di conseguenza, aggiungendo un termine di penalizzazione alla loss è possibile indurre i pesi del modello ad avere valori più piccoli.\n",
        "A seconda del tipo di penalizzazione, possiamo avere L1 (valore assoluto) o L2 (norma quadratica)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMWbtPQ__zPl"
      },
      "source": [
        "### Alleniamo il modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU4l9sFW_zPl"
      },
      "source": [
        "Per allenare un modello dentro Keras è sufficiente chiamare il metodo `.fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5OQBSSN_zPl",
        "outputId": "f9ddf0c0-32b0-4b9e-f9a0-a5b91e07d603"
      },
      "outputs": [],
      "source": [
        "help(model.fit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzFV8o1w_zPl",
        "outputId": "a806b6f8-41b1-4d9c-f708-59e50f6bf4d7"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x=train_X,\n",
        "    y=train_y,\n",
        "    epochs=500,\n",
        "    batch_size=train_X.shape[0]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy-tAQe5j6ub",
        "outputId": "afe0de7b-2c6d-40b3-c4d5-6b38754aa4fa"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lla funzione `.fit` restituisce uno storico di ciò che è accaduto durante il training in termini di metriche."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(history.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Questo è molto utile per poter visualizzare il comportamento del modello dopo il training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.lineplot(x=history.epoch, y=history.history['loss'])\n",
        "ax.set(xlabel='epoch', ylabel='loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ax = sns.lineplot(x=history.epoch, y=history.history['accuracy'])\n",
        "ax.set(xlabel='epoch', ylabel='accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_ayYvB_zPn"
      },
      "source": [
        "Finora abbiamo sempre lavorato sul training set, ma come va il nostro modello su dati su cui non si è mai allenato? Vediamolo tramite la funzione `.evaluate`, che ci restituisce i risultati delle metriche sui dati che forniamo al metodo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj4Rc2Tj_zPn",
        "outputId": "56b5ba0e-eb8d-4016-9821-d745dd9dc252"
      },
      "outputs": [],
      "source": [
        "metrics = model.evaluate(test_X, test_y)\n",
        "metrics # loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se vogliamo, possiamo anche farci restituire le predizioni su dati nuovi tramite la funzione `.predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(test_X)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In maniera equivalente, possiamo chiamare l'oggetto del modello come se fosse una funzione."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model(test_X)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfVNQGxN_zPo"
      },
      "source": [
        "Comunque, con un dataset giocattolo come MNIST possiamo sicuramente fare di meglio, ed è qui che entrano in gioco le __reti neurali deep__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qdJgSv_j_1d"
      },
      "source": [
        "# Validazione ed Early Stopping\n",
        "\n",
        "Durante il training delle reti neurali, è fondamentale avere uno strumento che ci permetta di monitorare in che modo si potrebbe comportare il nostro modello se dovesse predire dei dati su cui non si sta allenando durante una generica epoca di training. \n",
        "\n",
        "Solitamente, questo strumento viene rappresentato dal __validation set__, su cui facciamo delle predizioni, valutiamo le metriche di quelle predizioni, __ma non ci alleniamo mai__. Questo rappresenta il metodo più comune per valutare la qualità del modello durante la fase di learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La prima cosa da fare, è prendere il nostro training set e tirar fuori un pezzetto (solitamente tra il 5% e il 20%) da utilizzare come validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_X, eval_X, train_y, eval_y = train_test_split(\n",
        "    train_X, train_y,\n",
        "    test_size=0.15,\n",
        "    shuffle=True,\n",
        "    stratify=train_y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_X.shape, train_y.shape, eval_X.shape, eval_y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = K.Sequential()\n",
        "model.add(K.layers.Flatten())\n",
        "model.add(K.layers.Rescaling(scale=1/255.))\n",
        "#model.add(K.layers.Dense(1000, activation='relu')) # Nuovo layer non lineare\n",
        "model.add(K.layers.Dense(200, activation='relu')) # Nuovo layer non lineare\n",
        "model.add(K.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=K.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=K.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x=train_X, \n",
        "    y=train_y, \n",
        "    epochs=100, \n",
        "    batch_size=1000, # Questa volta cambiamo il batch size\n",
        "    validation_data=(eval_X, eval_y)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'epoch': history.epoch,\n",
        "    'loss': history.history['loss'],\n",
        "    'val_loss': history.history['val_loss']\n",
        "})\n",
        "ax = sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(results, ['epoch']))\n",
        "ax.set(xlabel='epoch', ylabel='loss value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'epoch': history.epoch,\n",
        "    'loss': history.history['accuracy'],\n",
        "    'val_loss': history.history['val_accuracy']\n",
        "})\n",
        "ax = sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(results, ['epoch']))\n",
        "ax.set(xlabel='epoch', ylabel='accuracy value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ora che abbiamo il validation set, possiamo anche utilizzarlo per decidere quando fermare il training, __senza preoccuparci del numero massimo di epoche__.\n",
        "\n",
        "Keras implementa l'early stopping sotto forma di `callback`. Le callbacks sono funzioni che vengono chiamate in momenti particolari del training, per esempio prima dell'inizio di un'epoca, alla fine di un'epoca, dopo un generico step di learning etc..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stopping = K.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    patience=5,\n",
        "    min_delta=0.0005,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = K.Sequential()\n",
        "model.add(K.layers.Flatten())\n",
        "model.add(K.layers.Rescaling(scale=1/255.))\n",
        "#model.add(K.layers.Dense(1000, activation='relu')) # Nuovo layer non lineare\n",
        "model.add(K.layers.Dense(200, activation='relu')) # Nuovo layer non lineare\n",
        "model.add(K.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer=K.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=K.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x=train_X, \n",
        "    y=train_y, \n",
        "    epochs=10000, \n",
        "    batch_size=1000,\n",
        "    validation_data=(eval_X, eval_y),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'epoch': history.epoch,\n",
        "    'loss': history.history['loss'],\n",
        "    'val_loss': history.history['val_loss']\n",
        "})\n",
        "ax = sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(results, ['epoch']))\n",
        "ax.set(xlabel='epoch', ylabel='loss value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = pd.DataFrame({\n",
        "    'epoch': history.epoch,\n",
        "    'loss': history.history['accuracy'],\n",
        "    'val_loss': history.history['val_accuracy']\n",
        "})\n",
        "ax = sns.lineplot(x='epoch', y='value', hue='variable', data=pd.melt(results, ['epoch']))\n",
        "ax.set(xlabel='epoch', ylabel='accuracy value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxk-4jYSyaCP"
      },
      "source": [
        "## Salvataggio e caricamento del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBMcK8_nIf5F"
      },
      "source": [
        "Ora che abbiamo un modello che potremmo anche voler riutilizzare, avere un metodo per il salvataggio e il caricamento è fondamentale.\n",
        "\n",
        "La  `model serialization` può essere utile anche quando usate colab, visto che il tempo di utilizzo è limitato e si può disconnettere nel mezzo del processo e potreste voler riprendere il training in seguito."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEdOYZpCycm2"
      },
      "outputs": [],
      "source": [
        "model.save('my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = K.models.load_model('my_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlP-jZzBzQcg"
      },
      "source": [
        "Ci sono parecchie altre opzioni. Salvataggio in formato H5, salvare solo i pesi, salvare solo l'architettura del modello, etc...  \n",
        "Guida alla serializzazione dei modelli: https://www.tensorflow.org/guide/keras/save_and_serialize"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('lab_keras')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "771535326852597fbb44ee6840cc5ca9054bcf91268df2c6d8f460ceb5cfa0ac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
